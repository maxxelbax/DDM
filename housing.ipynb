{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# %matplotlib qt5\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import numbers\n",
    "\n",
    "def auto_opt_pd_dtypes(df_: pd.DataFrame, inplace=False) -> Optional[pd.DataFrame]:\n",
    "    \"\"\" Automatically downcast Number dtypes for minimal possible,\n",
    "        will not touch other (datetime, str, object, etc)\n",
    "        :param df_: dataframe\n",
    "        :param inplace: if False, will return a copy of input dataset\n",
    "        :return: `None` if `inplace=True` or dataframe if `inplace=False`\n",
    "    \"\"\"\n",
    "    df_temp = df_ if inplace else df_.copy()\n",
    "    print(df_temp.info())\n",
    "\n",
    "    for col in df_temp.columns:\n",
    "        # integers\n",
    "        if issubclass(df_temp[col].dtypes.type, numbers.Integral):\n",
    "            # unsigned integers\n",
    "            if df_temp[col].min() >= 0:\n",
    "                df_temp[col] = pd.to_numeric(df_temp[col], downcast='unsigned')\n",
    "            # signed integers\n",
    "            else:\n",
    "                df_temp[col] = pd.to_numeric(df_temp[col], downcast='integer')\n",
    "        # other real numbers\n",
    "        elif issubclass(df_temp[col].dtypes.type, numbers.Real):\n",
    "            df_temp[col] = pd.to_numeric(df_temp[col], downcast='float')\n",
    "\n",
    "        elif issubclass(df_temp[col].dtypes.type, np.object_):\n",
    "            df_temp[col] = pd.Categorical(df_temp[col])\n",
    "\n",
    "    print(df_temp.info())\n",
    "    if not inplace:\n",
    "        return df_temp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ca8230c9be76ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('kc_house_data.csv', header='infer', delimiter=',', parse_dates=['date'])\n",
    "df = auto_opt_pd_dtypes(df)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e95ec76d9fdfa9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d4ec838bf130845",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['id'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cfaccb6fc28f202",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.loc[df['id'] == 795000620]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e227bc1e669c224e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "replace 0s with actual nan values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cae98b4e4a2d0d03"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].replace(0, np.nan)\n",
    "df['yr_renovated'] = df['yr_renovated'].replace(0, np.nan)\n",
    "df['yr_renovated'] = df['yr_renovated'].replace(1, np.nan)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457b0c3edff379c7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "label specific columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd425037d309ef3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ('id', 'date')]\n",
    "cols_log = ['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']\n",
    "\n",
    "# view is mostly 0\n",
    "cols_pairplot = [col for col in cols if col not in ('sqft_basement', 'zipcode', 'lat', 'long', 'view', 'grade', 'sqft_above', 'sqft_living15', 'sqft_lot15', 'floors', 'waterfront', 'condition')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3ead1cf8ba5ca33",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df.loc[df['bedrooms'] < 30]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9f75c01d876827b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_log = df.copy()\n",
    "df_log[cols_log] = np.log10(df_log[cols_log])\n",
    "\n",
    "df_log"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4700eceaa1a07879",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_num = df[cols]\n",
    "for k,v in df_num.items():\n",
    "    q1 = v.quantile(0.25)\n",
    "    q3 = v.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    v_outliers = v[(v <= q1 - 1.5 * iqr) | (v >= q3 + 1.5 * iqr)]\n",
    "    print(f'outliers in {k}: {len(v_outliers)/len(v)*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29aa3ee704a110f3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed1db6ff8d1af3ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df = df[df['sqft_lot'] <= 50_000]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49c4fda812a5dd3a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_num = df[cols]\n",
    "# for k,v in df_num.items():\n",
    "#     q1 = v.quantile(0.25)\n",
    "#     q3 = v.quantile(0.75)\n",
    "#     iqr = q3 - q1\n",
    "#     v_outliers = v[(v <= q1 - 1.5 * iqr) | (v >= q3 + 1.5 * iqr)]\n",
    "#     print(f'outliers in {k}: {len(v_outliers)/len(v)*100:.2f}%')\n",
    "# \n",
    "# df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "379d5a46c37a1234",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "boxplots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e46ac34e20eab3c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=4, figsize=(15, 8))\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df[cols].items():\n",
    "    sns.boxplot(y=k, data=df, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a2c426267a32ac9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ecdfplot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "656f5e5dcfb89137"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=4, figsize=(15, 8))\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df[cols].items():\n",
    "    sns.ecdfplot(x=k, data=df, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51c08f641248fb2f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "histogram/distribution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bba9d967046eac4d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=4, figsize=(15, 8))\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df[cols].items():\n",
    "    if k in cols_log:\n",
    "        sns.histplot(x=k, data=df, ax=axs[index], kde=True, log_scale=True)\n",
    "    else:\n",
    "        sns.histplot(x=k, data=df, ax=axs[index], kde=True, log_scale=False)\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18727023e253f48f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, nrows=3, figsize=(15, 8))\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df[list(set(cols) - set(cols_log))].items():\n",
    "    sns.histplot(x=k, data=df, ax=axs[index], kde=True, log_scale=False)\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1eda20b2a1d02112",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.pairplot(df[cols_pairplot])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c027947cf291787c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.heatmap(df[cols].corr('spearman')**2, annot=True)\n",
    "plt.title('r^2 using Pearson')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "889095920f7ddb45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[cols].corr()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee3e500451fee870",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[cols].corr('pearson')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324dbb28fc0abbe2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from pca import pca\n",
    "\n",
    "num_data = df[cols].fillna(0)\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "standardscaler = StandardScaler()\n",
    "\n",
    "cols_sel = [col for col in cols if col not in ('price', 'zipcode', 'lat', 'long')]\n",
    "x = pd.DataFrame(data=standardscaler.fit_transform(num_data[cols_sel]), columns=cols_sel)\n",
    "\n",
    "pca_input = x.dropna()\n",
    "model = PCA(n_components=2)\n",
    "pca_data = model.fit_transform(pca_input)\n",
    "\n",
    "num_data[['PCA 1', 'PCA 2']] = pca_data\n",
    "\n",
    "sns.scatterplot(data=num_data.sort_values(by='price', ascending=True), x='PCA 1', y='PCA 2', hue='price', palette='RdYlGn')\n",
    "plt.xlabel('PCA component 1')\n",
    "plt.ylabel('PCA component 2')\n",
    "plt.title('PCA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Explained variance by first 2 compononents: {sum(model.explained_variance_ratio_):.3f}')\n",
    "\n",
    "# model = pca(n_components=2)\n",
    "# pca_data = model.fit_transform(pca_input)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e56f15ca5cc1e6db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# model.biplot(alpha=0.2, s=30, color_arrow='r', figsize=(14, 8), arrowdict={'alpha': 1, 'color_weak': '#008808', 'scale_factor': 1}, dpi=80)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea105ddde5efcb0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(model.components_.shape[0]):\n",
    "    arr = np.abs(model.components_[i])\n",
    "    indices = np.argpartition(arr, -5)[-5:]\n",
    "    indices = indices[np.argsort(arr[indices])[::-1]]\n",
    "    input_cols = x.columns[indices]\n",
    "    values = model.components_[i][indices]\n",
    "    \n",
    "    print(f'PCA component {i}:')\n",
    "    for j in range(5):\n",
    "        print(f'{input_cols[j]}:\\t{values[j]:.3f}')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f02207bf4e28663",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.scatter(df['sqft_above']+df['sqft_basement'], df['sqft_living'])\n",
    "plt.xlabel('basement + above')\n",
    "plt.ylabel('sqft_living')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ac7d7993ba7c376",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, nrows=4, figsize=(15, 8), sharex=True, sharey=True)\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "\n",
    "for k, v in df[cols].items():\n",
    "    data = df.sort_values(k)\n",
    "\n",
    "    # Determine normalization\n",
    "    if k in cols_log:\n",
    "        # handle nonpositive values\n",
    "        cvals = data[k].to_numpy()\n",
    "        vmin = np.min(cvals[cvals > 0]) if np.any(cvals > 0) else 1e-6\n",
    "        norm = LogNorm(vmin=vmin, vmax=np.max(cvals))\n",
    "    else:\n",
    "        norm = None\n",
    "\n",
    "    sc = axs[index].scatter(\n",
    "        data['lat'],\n",
    "        data['long'],\n",
    "        c=data[k],\n",
    "        cmap='RdYlGn',\n",
    "        norm=norm,\n",
    "        alpha=0.6,\n",
    "        s=1,\n",
    "        linewidth=0\n",
    "    )\n",
    "\n",
    "    axs[index].set_title(k)\n",
    "    plt.colorbar(sc, ax=axs[index])\n",
    "\n",
    "    index += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7649c7a37441a032",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8461cab19b5e422",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.scatter(df['sqft_living'], df['sqft_living15'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2ee2a5bc6dc9e7f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "standardize df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81fd5f321d944aed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_standardized = df.copy()\n",
    "df_standardized[cols] = scaler.fit_transform(df[cols])\n",
    "\n",
    "df_standardized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2e6a284aefbda4c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "normalize df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "629fffab29b197b5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = df.copy()\n",
    "df_normalized[cols] = scaler.fit_transform(df[cols])\n",
    "\n",
    "df_normalized"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8afa7998df99920a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=5, nrows=4, figsize=(15, 8))\n",
    "\n",
    "index = 0\n",
    "axs = axs.flatten()\n",
    "for k,v in df_normalized[cols].items():\n",
    "    sns.boxplot(y=k, data=df_normalized, ax=axs[index])\n",
    "    index += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44a95ce9b02d492f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add suffixes to numeric columns\n",
    "std_df_renamed = df_standardized[cols].add_suffix(\"_std\")\n",
    "norm_df_renamed = df_normalized[cols].add_suffix(\"_norm\")\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df_pair = pd.concat([std_df_renamed, norm_df_renamed], axis=1)\n",
    "\n",
    "# sns.pairplot(df_pair)\n",
    "# plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1732aeb4d42bd34",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_log['yr_renovated_new'] = 2025 - df_log['yr_renovated']\n",
    "df_log['yr_built_new'] = 2025 - df_log['yr_built']\n",
    "df_modelling = df_log.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T21:57:59.601424Z",
     "start_time": "2026-01-13T21:57:59.589377Z"
    }
   },
   "id": "c4b4adbff5eb53e",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               id       date     price  bedrooms  sqft_lot  floors  \\\n0      7129300520 2014-10-13  5.346157         3  3.752048     1.0   \n1      6414100192 2014-12-09  5.730783         3  3.859859     2.0   \n2      5631500400 2015-02-25  5.255272         2  4.000000     1.0   \n3      2487200875 2014-12-09  5.781037         4  3.698970     1.0   \n4      1954400510 2015-02-18  5.707570         3  3.907411     1.0   \n...           ...        ...       ...       ...       ...     ...   \n21608   263000018 2014-05-21  5.556303         3  3.053463     3.0   \n21609  6600060120 2015-02-23  5.602060         4  3.764400     2.0   \n21610  1523300141 2014-06-23  5.604335         2  3.130334     2.0   \n21611   291310100 2015-01-16  5.602060         3  3.378034     2.0   \n21612  1523300157 2014-10-15  5.511883         2  3.031812     2.0   \n\n       waterfront  view  condition  sqft_above  sqft_basement        lat  \\\n0               0     0          3    3.071882            NaN  47.511200   \n1               0     0          3    3.336460       2.602060  47.721001   \n2               0     0          3    2.886491            NaN  47.737900   \n3               0     0          5    3.021189       2.959041  47.520802   \n4               0     0          3    3.225309            NaN  47.616798   \n...           ...   ...        ...         ...            ...        ...   \n21608           0     0          3    3.184691            NaN  47.699299   \n21609           0     0          3    3.363612            NaN  47.510700   \n21610           0     0          3    3.008600            NaN  47.594398   \n21611           0     0          3    3.204120            NaN  47.534500   \n21612           0     0          3    3.008600            NaN  47.594101   \n\n             long  yr_renovated_new  yr_built_new  \n0     -122.257004               NaN            70  \n1     -122.319000              34.0            74  \n2     -122.233002               NaN            92  \n3     -122.392998               NaN            60  \n4     -122.044998               NaN            38  \n...           ...               ...           ...  \n21608 -122.346001               NaN            16  \n21609 -122.362000               NaN            11  \n21610 -122.299004               NaN            16  \n21611 -122.069000               NaN            21  \n21612 -122.299004               NaN            17  \n\n[21612 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>condition</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>yr_renovated_new</th>\n      <th>yr_built_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7129300520</td>\n      <td>2014-10-13</td>\n      <td>5.346157</td>\n      <td>3</td>\n      <td>3.752048</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.071882</td>\n      <td>NaN</td>\n      <td>47.511200</td>\n      <td>-122.257004</td>\n      <td>NaN</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6414100192</td>\n      <td>2014-12-09</td>\n      <td>5.730783</td>\n      <td>3</td>\n      <td>3.859859</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.336460</td>\n      <td>2.602060</td>\n      <td>47.721001</td>\n      <td>-122.319000</td>\n      <td>34.0</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5631500400</td>\n      <td>2015-02-25</td>\n      <td>5.255272</td>\n      <td>2</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.886491</td>\n      <td>NaN</td>\n      <td>47.737900</td>\n      <td>-122.233002</td>\n      <td>NaN</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2487200875</td>\n      <td>2014-12-09</td>\n      <td>5.781037</td>\n      <td>4</td>\n      <td>3.698970</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3.021189</td>\n      <td>2.959041</td>\n      <td>47.520802</td>\n      <td>-122.392998</td>\n      <td>NaN</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1954400510</td>\n      <td>2015-02-18</td>\n      <td>5.707570</td>\n      <td>3</td>\n      <td>3.907411</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.225309</td>\n      <td>NaN</td>\n      <td>47.616798</td>\n      <td>-122.044998</td>\n      <td>NaN</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21608</th>\n      <td>263000018</td>\n      <td>2014-05-21</td>\n      <td>5.556303</td>\n      <td>3</td>\n      <td>3.053463</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.184691</td>\n      <td>NaN</td>\n      <td>47.699299</td>\n      <td>-122.346001</td>\n      <td>NaN</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>21609</th>\n      <td>6600060120</td>\n      <td>2015-02-23</td>\n      <td>5.602060</td>\n      <td>4</td>\n      <td>3.764400</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.363612</td>\n      <td>NaN</td>\n      <td>47.510700</td>\n      <td>-122.362000</td>\n      <td>NaN</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>21610</th>\n      <td>1523300141</td>\n      <td>2014-06-23</td>\n      <td>5.604335</td>\n      <td>2</td>\n      <td>3.130334</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.008600</td>\n      <td>NaN</td>\n      <td>47.594398</td>\n      <td>-122.299004</td>\n      <td>NaN</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>21611</th>\n      <td>291310100</td>\n      <td>2015-01-16</td>\n      <td>5.602060</td>\n      <td>3</td>\n      <td>3.378034</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.204120</td>\n      <td>NaN</td>\n      <td>47.534500</td>\n      <td>-122.069000</td>\n      <td>NaN</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>21612</th>\n      <td>1523300157</td>\n      <td>2014-10-15</td>\n      <td>5.511883</td>\n      <td>2</td>\n      <td>3.031812</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.008600</td>\n      <td>NaN</td>\n      <td>47.594101</td>\n      <td>-122.299004</td>\n      <td>NaN</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n<p>21612 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelling = df_modelling[[col for col in df_modelling.columns if col not in ('zipcode', 'yr_built', 'yr_renovated', 'bathrooms', 'sqft_living', 'grade', 'sqft_living15', 'sqft_lot15')]]\n",
    "df_modelling"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T21:58:00.381954Z",
     "start_time": "2026-01-13T21:58:00.346729Z"
    }
   },
   "id": "6d76877b5025c6f1",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               id       date     price  bedrooms  sqft_lot  floors  \\\n0         1000102 2015-04-22  5.477121         6  3.971879     2.0   \n1         1200019 2014-05-08  5.811240         4  4.415574     1.0   \n2         1200021 2014-08-11  5.602060         3  4.633468     1.0   \n3         2800031 2015-04-01  5.371068         3  3.880756     1.5   \n4         3600057 2015-03-19  5.604766         4  3.544564     1.0   \n...           ...        ...       ...       ...       ...     ...   \n21430  9842300095 2014-07-25  5.562293         5  3.619928     1.5   \n21431  9842300485 2015-03-11  5.579783         2  3.867585     1.0   \n21432  9842300540 2014-06-24  5.530200         3  3.615740     1.0   \n21433  9895000040 2014-07-03  5.601952         2  3.002166     1.5   \n21434  9900000190 2014-10-30  5.429672         3  3.908485     1.0   \n\n       waterfront  view  condition  sqft_above  sqft_basement        lat  \\\n0               0     0          3    3.380211       0.000000  47.326199   \n1               0     0          4    3.064458       2.954243  47.444401   \n2               0     0          3    3.164353       0.000000  47.443401   \n3               0     0          4    3.004321       2.623249  47.478298   \n4               0     0          3    2.880814       2.949390  47.580299   \n...           ...   ...        ...         ...            ...        ...   \n21430           0     0          3    3.204120       0.000000  47.529701   \n21431           0     0          5    2.924279       2.301030  47.528500   \n21432           0     0          4    2.857332       2.579784  47.529598   \n21433           0     0          3    2.954242       2.707570  47.544601   \n21434           0     0          3    2.944483       2.643453  47.469700   \n\n             long  yr_renovated_new  yr_built_new  \n0     -122.213997              34.0            34  \n1     -122.350998              78.0            78  \n2     -122.347000              73.0            73  \n3     -122.264999              95.0            95  \n4     -122.293999              12.0            74  \n...           ...               ...           ...  \n21430 -122.380997              98.0            98  \n21431 -122.377998              86.0            86  \n21432 -122.378998              83.0            83  \n21433 -122.017998              14.0            14  \n21434 -122.350998              82.0            82  \n\n[21435 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>condition</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>yr_renovated_new</th>\n      <th>yr_built_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000102</td>\n      <td>2015-04-22</td>\n      <td>5.477121</td>\n      <td>6</td>\n      <td>3.971879</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.380211</td>\n      <td>0.000000</td>\n      <td>47.326199</td>\n      <td>-122.213997</td>\n      <td>34.0</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1200019</td>\n      <td>2014-05-08</td>\n      <td>5.811240</td>\n      <td>4</td>\n      <td>4.415574</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3.064458</td>\n      <td>2.954243</td>\n      <td>47.444401</td>\n      <td>-122.350998</td>\n      <td>78.0</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200021</td>\n      <td>2014-08-11</td>\n      <td>5.602060</td>\n      <td>3</td>\n      <td>4.633468</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.164353</td>\n      <td>0.000000</td>\n      <td>47.443401</td>\n      <td>-122.347000</td>\n      <td>73.0</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2800031</td>\n      <td>2015-04-01</td>\n      <td>5.371068</td>\n      <td>3</td>\n      <td>3.880756</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>3.004321</td>\n      <td>2.623249</td>\n      <td>47.478298</td>\n      <td>-122.264999</td>\n      <td>95.0</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3600057</td>\n      <td>2015-03-19</td>\n      <td>5.604766</td>\n      <td>4</td>\n      <td>3.544564</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.880814</td>\n      <td>2.949390</td>\n      <td>47.580299</td>\n      <td>-122.293999</td>\n      <td>12.0</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21430</th>\n      <td>9842300095</td>\n      <td>2014-07-25</td>\n      <td>5.562293</td>\n      <td>5</td>\n      <td>3.619928</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3.204120</td>\n      <td>0.000000</td>\n      <td>47.529701</td>\n      <td>-122.380997</td>\n      <td>98.0</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>21431</th>\n      <td>9842300485</td>\n      <td>2015-03-11</td>\n      <td>5.579783</td>\n      <td>2</td>\n      <td>3.867585</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2.924279</td>\n      <td>2.301030</td>\n      <td>47.528500</td>\n      <td>-122.377998</td>\n      <td>86.0</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>21432</th>\n      <td>9842300540</td>\n      <td>2014-06-24</td>\n      <td>5.530200</td>\n      <td>3</td>\n      <td>3.615740</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2.857332</td>\n      <td>2.579784</td>\n      <td>47.529598</td>\n      <td>-122.378998</td>\n      <td>83.0</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>21433</th>\n      <td>9895000040</td>\n      <td>2014-07-03</td>\n      <td>5.601952</td>\n      <td>2</td>\n      <td>3.002166</td>\n      <td>1.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.954242</td>\n      <td>2.707570</td>\n      <td>47.544601</td>\n      <td>-122.017998</td>\n      <td>14.0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>21434</th>\n      <td>9900000190</td>\n      <td>2014-10-30</td>\n      <td>5.429672</td>\n      <td>3</td>\n      <td>3.908485</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.944483</td>\n      <td>2.643453</td>\n      <td>47.469700</td>\n      <td>-122.350998</td>\n      <td>82.0</td>\n      <td>82</td>\n    </tr>\n  </tbody>\n</table>\n<p>21435 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modelling = df_modelling.sort_values('date').groupby('id').agg('last').reset_index()\n",
    "df_modelling.loc[df_modelling['yr_renovated_new'].isna(), 'yr_renovated_new'] = df_modelling['yr_built_new']\n",
    "df_modelling['sqft_basement'] = df_modelling['sqft_basement'].fillna(0)\n",
    "df_modelling"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T21:58:01.236800Z",
     "start_time": "2026-01-13T21:58:01.202176Z"
    }
   },
   "id": "e2157ec8b3500226",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               id       date     price  bedrooms  sqft_lot  floors  \\\n0         1000102 2015-04-22  0.299320  0.545455  0.358633     0.4   \n1         1200019 2014-05-08  0.465429  0.363636  0.485337     0.0   \n2         1200021 2014-08-11  0.361434  0.272727  0.547560     0.0   \n3         2800031 2015-04-01  0.246594  0.272727  0.332612     0.2   \n4         3600057 2015-03-19  0.362779  0.363636  0.236607     0.0   \n...           ...        ...       ...       ...       ...     ...   \n21430  9842300095 2014-07-25  0.341663  0.454545  0.258129     0.2   \n21431  9842300485 2015-03-11  0.350359  0.181818  0.328851     0.0   \n21432  9842300540 2014-06-24  0.325708  0.272727  0.256933     0.0   \n21433  9895000040 2014-07-03  0.361380  0.181818  0.081718     0.2   \n21434  9900000190 2014-10-30  0.275730  0.272727  0.340530     0.0   \n\n       waterfront  view  condition  sqft_above  sqft_basement       lat  \\\n0             0.0   0.0       0.50    0.607344       0.000000  0.273925   \n1             0.0   0.0       0.75    0.398401       0.802119  0.464053   \n2             0.0   0.0       0.50    0.464504       0.000000  0.462445   \n3             0.0   0.0       0.75    0.358607       0.712250  0.518576   \n4             0.0   0.0       0.50    0.276878       0.800802  0.682645   \n...           ...   ...        ...         ...            ...       ...   \n21430         0.0   0.0       0.50    0.490819       0.000000  0.601258   \n21431         0.0   0.0       1.00    0.305640       0.624763  0.599325   \n21432         0.0   0.0       0.75    0.261340       0.700448  0.601092   \n21433         0.0   0.0       0.50    0.325468       0.735144  0.625225   \n21434         0.0   0.0       0.50    0.319010       0.717735  0.504746   \n\n           long  yr_renovated_new  yr_built_new  \n0      0.253324          0.208696      0.208696  \n1      0.139535          0.591304      0.591304  \n2      0.142855          0.547826      0.547826  \n3      0.210963          0.739130      0.739130  \n4      0.186877          0.017391      0.556522  \n...         ...               ...           ...  \n21430  0.114619          0.765217      0.765217  \n21431  0.117109          0.660870      0.660870  \n21432  0.116279          0.634783      0.634783  \n21433  0.416114          0.034783      0.034783  \n21434  0.139535          0.626087      0.626087  \n\n[21435 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>condition</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>yr_renovated_new</th>\n      <th>yr_built_new</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000102</td>\n      <td>2015-04-22</td>\n      <td>0.299320</td>\n      <td>0.545455</td>\n      <td>0.358633</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.607344</td>\n      <td>0.000000</td>\n      <td>0.273925</td>\n      <td>0.253324</td>\n      <td>0.208696</td>\n      <td>0.208696</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1200019</td>\n      <td>2014-05-08</td>\n      <td>0.465429</td>\n      <td>0.363636</td>\n      <td>0.485337</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.398401</td>\n      <td>0.802119</td>\n      <td>0.464053</td>\n      <td>0.139535</td>\n      <td>0.591304</td>\n      <td>0.591304</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200021</td>\n      <td>2014-08-11</td>\n      <td>0.361434</td>\n      <td>0.272727</td>\n      <td>0.547560</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.464504</td>\n      <td>0.000000</td>\n      <td>0.462445</td>\n      <td>0.142855</td>\n      <td>0.547826</td>\n      <td>0.547826</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2800031</td>\n      <td>2015-04-01</td>\n      <td>0.246594</td>\n      <td>0.272727</td>\n      <td>0.332612</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.358607</td>\n      <td>0.712250</td>\n      <td>0.518576</td>\n      <td>0.210963</td>\n      <td>0.739130</td>\n      <td>0.739130</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3600057</td>\n      <td>2015-03-19</td>\n      <td>0.362779</td>\n      <td>0.363636</td>\n      <td>0.236607</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.276878</td>\n      <td>0.800802</td>\n      <td>0.682645</td>\n      <td>0.186877</td>\n      <td>0.017391</td>\n      <td>0.556522</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21430</th>\n      <td>9842300095</td>\n      <td>2014-07-25</td>\n      <td>0.341663</td>\n      <td>0.454545</td>\n      <td>0.258129</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.490819</td>\n      <td>0.000000</td>\n      <td>0.601258</td>\n      <td>0.114619</td>\n      <td>0.765217</td>\n      <td>0.765217</td>\n    </tr>\n    <tr>\n      <th>21431</th>\n      <td>9842300485</td>\n      <td>2015-03-11</td>\n      <td>0.350359</td>\n      <td>0.181818</td>\n      <td>0.328851</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.305640</td>\n      <td>0.624763</td>\n      <td>0.599325</td>\n      <td>0.117109</td>\n      <td>0.660870</td>\n      <td>0.660870</td>\n    </tr>\n    <tr>\n      <th>21432</th>\n      <td>9842300540</td>\n      <td>2014-06-24</td>\n      <td>0.325708</td>\n      <td>0.272727</td>\n      <td>0.256933</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.261340</td>\n      <td>0.700448</td>\n      <td>0.601092</td>\n      <td>0.116279</td>\n      <td>0.634783</td>\n      <td>0.634783</td>\n    </tr>\n    <tr>\n      <th>21433</th>\n      <td>9895000040</td>\n      <td>2014-07-03</td>\n      <td>0.361380</td>\n      <td>0.181818</td>\n      <td>0.081718</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.325468</td>\n      <td>0.735144</td>\n      <td>0.625225</td>\n      <td>0.416114</td>\n      <td>0.034783</td>\n      <td>0.034783</td>\n    </tr>\n    <tr>\n      <th>21434</th>\n      <td>9900000190</td>\n      <td>2014-10-30</td>\n      <td>0.275730</td>\n      <td>0.272727</td>\n      <td>0.340530</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.319010</td>\n      <td>0.717735</td>\n      <td>0.504746</td>\n      <td>0.139535</td>\n      <td>0.626087</td>\n      <td>0.626087</td>\n    </tr>\n  </tbody>\n</table>\n<p>21435 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_norm = [col for col in df_modelling.columns if col not in ('id', 'date')]\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = df_modelling.copy()\n",
    "df_normalized[cols_norm] = scaler.fit_transform(df_modelling[cols_norm])\n",
    "\n",
    "df_normalized"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T21:58:03.076454Z",
     "start_time": "2026-01-13T21:58:03.041744Z"
    }
   },
   "id": "2c1be047c6ffa5ed",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bo112\\AppData\\Local\\Temp\\ipykernel_9748\\3956833134.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  num_data[['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4', 'PCA 5']] = pca_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by first 5 compononents: 0.726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from pca import pca\n",
    "\n",
    "num_data = df_modelling[cols_norm]\n",
    "\n",
    "minmaxscaler = MinMaxScaler()\n",
    "standardscaler = StandardScaler()\n",
    "\n",
    "x = pd.DataFrame(data=standardscaler.fit_transform(num_data[cols_norm]), columns=cols_norm)\n",
    "\n",
    "pca_input = x.dropna()\n",
    "model = PCA(n_components=5)\n",
    "pca_data = model.fit_transform(pca_input)\n",
    "\n",
    "num_data[['PCA 1', 'PCA 2', 'PCA 3', 'PCA 4', 'PCA 5']] = pca_data\n",
    "\n",
    "sns.scatterplot(data=num_data.sort_values(by='price', ascending=True), x='PCA 1', y='PCA 2', hue='price', palette='RdYlGn')\n",
    "plt.xlabel('PCA component 1')\n",
    "plt.ylabel('PCA component 2')\n",
    "plt.title('PCA')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Explained variance by first 5 compononents: {sum(model.explained_variance_ratio_):.3f}')\n",
    "\n",
    "# model = pca(n_components=2)\n",
    "# pca_data = model.fit_transform(pca_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:04:05.155660Z",
     "start_time": "2026-01-14T01:04:04.877348Z"
    }
   },
   "id": "e9ed9cd3925eb394",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T22:16:35.110747Z",
     "start_time": "2026-01-13T22:16:35.093615Z"
    }
   },
   "id": "fc9ba3dbefc01857",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:29<00:00, 33.64s/it]\n",
      "100%|██████████| 8/8 [04:18<00:00, 32.30s/it]\n",
      "100%|██████████| 8/8 [03:55<00:00, 29.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "linkage_methods = ['ward', 'average', 'complete']\n",
    "for l in range(len(linkage_methods)):\n",
    "    method = linkage_methods[l]\n",
    "    results_silhouette = {}\n",
    "    results_dbi = {}\n",
    "    \n",
    "    for i in tqdm(range(3, 11)):\n",
    "        X = df_normalized[cols_norm]\n",
    "        \n",
    "        # setting distance_threshold=0 ensures we compute the full tree.\n",
    "        model = AgglomerativeClustering(distance_threshold=None, n_clusters=i, linkage=method)\n",
    "        \n",
    "        model = model.fit(X)\n",
    "        labels = model.labels_\n",
    "        results_silhouette[i] = silhouette_score(X, labels)\n",
    "        results_dbi[i] = davies_bouldin_score(X, labels)\n",
    "        \n",
    "    plt.plot(results_silhouette.keys(), results_silhouette.values())\n",
    "    plt.title(f\"Silhouette Score - Reduced Data ('{method}')\")\n",
    "    plt.xlabel('n Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'silhouette_reduced_{method}')\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot(results_dbi.keys(), results_dbi.values())\n",
    "    plt.title(f\"Davis-Bouldin Score - Reduced Data ('{method}')\")\n",
    "    plt.xlabel('n Clusters')\n",
    "    plt.ylabel('Davis-Bouldin Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'dbi_reduced_{method}')\n",
    "    plt.clf()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:10:34.645443Z",
     "start_time": "2026-01-13T22:57:50.226597Z"
    }
   },
   "id": "48de909e2cbf7ca8",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   min_cluster_size_pct  min_cluster_size  min_samples  metric  \\\n0                     1                 2            3       4   \n1                     5                 2            3       4   \n\n   cluster_selection  \n0                  5  \n1                  5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_cluster_size_pct</th>\n      <th>min_cluster_size</th>\n      <th>min_samples</th>\n      <th>metric</th>\n      <th>cluster_selection</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1=pd.DataFrame(data={'min_cluster_size_pct': 1,\n",
    "                   'min_cluster_size': 2,\n",
    "                   'min_samples': 3,\n",
    "                   'metric': 4,\n",
    "                   'cluster_selection': 5}, \n",
    "             index=[0])\n",
    "temp2=pd.DataFrame(data={'min_cluster_size_pct': 5,\n",
    "                   'min_cluster_size': 2,\n",
    "                   'min_samples': 3,\n",
    "                   'metric': 4,\n",
    "                   'cluster_selection': 5}, \n",
    "             index=[0])\n",
    "pd.concat([temp1, temp2]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T00:08:06.587982Z",
     "start_time": "2026-01-14T00:08:06.562107Z"
    }
   },
   "id": "2f9ebd02b3671638",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]C:\\Users\\bo112\\AppData\\Local\\Temp\\ipykernel_9748\\161196034.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_settings = pd.concat([df_settings, temp]).reset_index(drop=True)\n",
      "100%|██████████| 4/4 [02:43<00:00, 40.89s/it]\n",
      "100%|██████████| 4/4 [02:41<00:00, 40.49s/it]\n",
      "100%|██████████| 4/4 [02:47<00:00, 41.94s/it]\n",
      "100%|██████████| 4/4 [02:50<00:00, 42.63s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import HDBSCAN\n",
    "import umap\n",
    "\n",
    "setting_cols = ['n_components', 'min_cluster_size_pct', 'min_cluster_size', 'min_samples', 'n_clusters',\n",
    "                'noise_pct', 'silhouette_score', 'dbi_score']\n",
    "df_settings = pd.DataFrame(columns=setting_cols)\n",
    "\n",
    "\n",
    "for n_components in (4, 6, 8, 10):\n",
    "    reducer = umap.UMAP(n_components=n_components)\n",
    "    data = df_modelling[[col for col in df_modelling.columns if col not in ('id', 'date')]].values\n",
    "    scaled_data = StandardScaler().fit_transform(data)\n",
    "    embedding = reducer.fit_transform(scaled_data)\n",
    "    X = embedding\n",
    "    for mcs_pct in tqdm((0.05, 0.025, 0.01, 0.005)):\n",
    "        mcs = round(len(df_modelling) * mcs_pct)\n",
    "        min_samples_list = [round(i * mcs) for i in [0.5, 0.25, 0.1, 0.05]]\n",
    "        for min_samples in min_samples_list:\n",
    "            clusterer = HDBSCAN(\n",
    "                min_cluster_size=mcs,\n",
    "                min_samples=min_samples,\n",
    "                metric=\"euclidean\"\n",
    "            )\n",
    "            labels = clusterer.fit_predict(X)\n",
    "    \n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            noise_frac = np.mean(labels == -1)\n",
    "    \n",
    "            temp = pd.DataFrame(data={'n_components': n_components,\n",
    "                                      'min_cluster_size_pct': mcs_pct,\n",
    "                                      'min_cluster_size': mcs,\n",
    "                                      'min_samples': min_samples,\n",
    "                                      'n_clusters': n_clusters,\n",
    "                                      'noise_pct': noise_frac,\n",
    "                                      'silhouette_score': silhouette_score(X, labels),\n",
    "                                      'dbi_score': davies_bouldin_score(X, labels)\n",
    "                                      },\n",
    "                                index=[0])\n",
    "            df_settings = pd.concat([df_settings, temp]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:36:40.872056Z",
     "start_time": "2026-01-14T01:25:21.751066Z"
    }
   },
   "id": "19ab8323146b2b76",
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_settings.to_csv('HDBSCAN_parameter_results.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:36:40.902017Z",
     "start_time": "2026-01-14T01:36:40.874554Z"
    }
   },
   "id": "be028fb0231a995",
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.PairGrid at 0x1eddf8c2e00>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pairplot(df_settings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:40:48.078659Z",
     "start_time": "2026-01-14T01:40:43.633524Z"
    }
   },
   "id": "c63b350184ad43a2",
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: xlabel='cluster_selection', ylabel='dbi_score'>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.boxplot(df_settings, x='cluster_selection', y='dbi_score')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:18:26.933287Z",
     "start_time": "2026-01-14T01:18:26.853287Z"
    }
   },
   "id": "5fb69606e1cb0e9b",
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.plot(n_clusters_list, results_silhouette.values())\n",
    "plt.title(f\"Silhouette Score - Reduced Data (HDBSCAN)\")\n",
    "plt.xlabel('n Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'silhouette_reduced_HDBSCAN_clusters')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(results_silhouette.keys(), results_silhouette.values())\n",
    "plt.title(f\"Silhouette Score - Reduced Data (HDBSCAN)\")\n",
    "plt.xlabel('min_clusters/N [%]')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'silhouette_reduced_HDBSCAN_percentage')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(n_clusters_list, results_dbi.values())\n",
    "plt.title(f\"Davis-Bouldin Score - Reduced Data (HDBSCAN)\")\n",
    "plt.xlabel('n Clusters')\n",
    "plt.ylabel('Davis-Bouldin Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'dbi_reduced_HDBSCAN_clusters')\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(results_dbi.keys(), results_dbi.values())\n",
    "plt.title(f\"Davis-Bouldin Score - Reduced Data (HDBSCAN)\")\n",
    "plt.xlabel('min_clusters/N [%]')\n",
    "plt.ylabel('Davis-Bouldin Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'dbi_reduced_HDBSCAN_percentage')\n",
    "plt.clf()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:32:37.353946Z",
     "start_time": "2026-01-13T23:32:36.754819Z"
    }
   },
   "id": "8594b6e81038bac9",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mcs, n_clusters, noise_frac, stability = zip(*results)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mcs, n_clusters)\n",
    "plt.xlabel(\"min_cluster_size\")\n",
    "plt.ylabel(\"Number of clusters\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mcs, noise_frac)\n",
    "plt.xlabel(\"min_cluster_size\")\n",
    "plt.ylabel(\"Noise fraction\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mcs, stability)\n",
    "plt.xlabel(\"min_cluster_size\")\n",
    "plt.ylabel(\"Mean cluster stability\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:34:03.921515Z",
     "start_time": "2026-01-13T23:34:03.671224Z"
    }
   },
   "id": "fe52b898d1c5d115",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = df_normalized[cols_norm]\n",
    "\n",
    "# setting distance_threshold=0 ensures we compute the full tree.\n",
    "model = AgglomerativeClustering(distance_threshold=None, n_clusters=6, linkage='ward')\n",
    "\n",
    "model = model.fit(X)\n",
    "labels = model.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:27:32.119416Z",
     "start_time": "2026-01-13T23:27:14.529862Z"
    }
   },
   "id": "99a3b5c6fcc484f2",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "# plot the top three levels of the dendrogram\n",
    "plot_dendrogram(model, truncate_mode=\"level\", p=3)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "490357b24dcf3d81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=6)\n",
    "data = df_modelling[[col for col in df_modelling.columns if col not in ('id', 'date')]].values\n",
    "scaled_data = StandardScaler().fit_transform(data)\n",
    "embedding = reducer.fit_transform(scaled_data)\n",
    "X = embedding\n",
    "mcs = round(len(df_modelling) * 0.025)\n",
    "min_samples = round(mcs * 0.25)\n",
    "clusterer = HDBSCAN(\n",
    "    min_cluster_size=mcs,\n",
    "    min_samples=min_samples,\n",
    "    metric=\"euclidean\"\n",
    ")\n",
    "labels = clusterer.fit_predict(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:47:52.467751Z",
     "start_time": "2026-01-14T01:47:42.273120Z"
    }
   },
   "id": "7f975124754f9cb3",
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import umap"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:19:56.890571Z",
     "start_time": "2026-01-13T23:19:45.611134Z"
    }
   },
   "id": "c4a277632dbc213c",
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = df_modelling[cols_norm].values\n",
    "scaled_data = StandardScaler().fit_transform(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:46:09.953652Z",
     "start_time": "2026-01-14T01:46:09.941318Z"
    }
   },
   "id": "52859ca3e196d983",
   "execution_count": 137
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:48:30.598488Z",
     "start_time": "2026-01-14T01:48:30.570730Z"
    }
   },
   "id": "fbd6d45c0d38d5d6",
   "execution_count": 147
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(21435, 2)"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = reducer.fit_transform(scaled_data)\n",
    "embedding.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:48:36.640226Z",
     "start_time": "2026-01-14T01:48:31.092523Z"
    }
   },
   "id": "1e135fad993236e7",
   "execution_count": 148
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(data=embedding)\n",
    "df_results = pd.concat([df_results, df_modelling], axis=1)\n",
    "df_results['label'] = labels\n",
    "# df_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:48:36.655743Z",
     "start_time": "2026-01-14T01:48:36.642827Z"
    }
   },
   "id": "ab4bcdd49c74fd14",
   "execution_count": 149
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "col = 'label'\n",
    "results_sorted = df_results.sort_values(col)\n",
    "plt.scatter(x=results_sorted.iloc[:, 0], y=results_sorted.iloc[:, 1], s=3, c=results_sorted[col], cmap='tab10_r', alpha=0.7)\n",
    "plt.colorbar()\n",
    "plt.title('Hierarchical Clustering on projected Data (n=6, linkage=ward)')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('hierarchical_n6_ward_projected')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:48:48.732723Z",
     "start_time": "2026-01-14T01:48:48.609703Z"
    }
   },
   "id": "cfc8e99f27e286cd",
   "execution_count": 152
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "               mean        median           std         max            min\nlabel                                                                     \n-1     1.340663e+06  949974.96875  1.091034e+06  7062500.50  285000.062500\n 0     5.064622e+05  474800.12500  1.829808e+05  1850000.50  204999.953125\n 1     4.393474e+05  375000.06250  2.571294e+05  2719999.75   88999.984375\n 2     4.847778e+05  415000.09375  2.805156e+05  4489000.50   74999.960938\n 3     5.636593e+05  517999.93750  2.920550e+05  3300001.75  133999.984375\n 4     5.539474e+05  468999.75000  3.506390e+05  5570001.50  100000.000000\n 5     8.913117e+05  749999.62500  5.754987e+05  7700001.50  153999.921875",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>median</th>\n      <th>std</th>\n      <th>max</th>\n      <th>min</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-1</th>\n      <td>1.340663e+06</td>\n      <td>949974.96875</td>\n      <td>1.091034e+06</td>\n      <td>7062500.50</td>\n      <td>285000.062500</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5.064622e+05</td>\n      <td>474800.12500</td>\n      <td>1.829808e+05</td>\n      <td>1850000.50</td>\n      <td>204999.953125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.393474e+05</td>\n      <td>375000.06250</td>\n      <td>2.571294e+05</td>\n      <td>2719999.75</td>\n      <td>88999.984375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.847778e+05</td>\n      <td>415000.09375</td>\n      <td>2.805156e+05</td>\n      <td>4489000.50</td>\n      <td>74999.960938</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.636593e+05</td>\n      <td>517999.93750</td>\n      <td>2.920550e+05</td>\n      <td>3300001.75</td>\n      <td>133999.984375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.539474e+05</td>\n      <td>468999.75000</td>\n      <td>3.506390e+05</td>\n      <td>5570001.50</td>\n      <td>100000.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8.913117e+05</td>\n      <td>749999.62500</td>\n      <td>5.754987e+05</td>\n      <td>7700001.50</td>\n      <td>153999.921875</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['price_real'] = 10**df_results['price']\n",
    "cluster_data = df_results.groupby('label')['price_real'].agg(['mean', 'median', 'std', 'max', 'min'])\n",
    "cluster_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:49:08.863725Z",
     "start_time": "2026-01-14T01:49:08.846798Z"
    }
   },
   "id": "e6f10037217ce3d8",
   "execution_count": 153
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14-01-2026 02:49:09] [matplotlib.category] [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "[14-01-2026 02:49:09] [matplotlib.category] [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Axes: xlabel='label', ylabel='price_real'>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.boxplot(df_results, x='label', y='price_real')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:49:09.907308Z",
     "start_time": "2026-01-14T01:49:09.779637Z"
    }
   },
   "id": "44c8d1c8a5e00d15",
   "execution_count": 154
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14-01-2026 02:49:13] [matplotlib.category] [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "[14-01-2026 02:49:13] [matplotlib.category] [INFO] Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Axes: xlabel='label', ylabel='price'>"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.boxplot(df_results, x='label', y='price')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:49:13.661969Z",
     "start_time": "2026-01-14T01:49:13.514248Z"
    }
   },
   "id": "faa510c1cfc51a67",
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.scatter(results_sorted['lat'], results_sorted['long'], c=results_sorted['label'], s=4, alpha=0.6, cmap='tab10_r')\n",
    "plt.colorbar()\n",
    "plt.title('Hierarchical Clustering on projected Data (n=6, linkage=ward)')\n",
    "plt.xlabel('Lat.')\n",
    "plt.ylabel('Long.')\n",
    "plt.tight_layout()\n",
    "plt.savefig('hierarchical_n6_ward_coords')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-14T01:49:18.638553Z",
     "start_time": "2026-01-14T01:49:18.224205Z"
    }
   },
   "id": "8db919d41c167925",
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-13T23:23:13.382599Z",
     "start_time": "2026-01-13T23:23:13.105903Z"
    }
   },
   "id": "9a1690b4d30f8994",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c94bc79c1d2b494"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
